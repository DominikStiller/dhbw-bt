After having regarded the theoretical foundations of streaming, we now look at existing implementations of stream transport and processing platforms that are available to the public (some companies have custom platforms for internal use only). We will prsent them under the aspects of correctness, fault tolerance, latency and scalability.





\section{Stream Transport Platforms}
Stream transport platforms are responsible for moving streams between producers and consumers, but may also store them for replay. Theoretically, any message queue or publish--subscribe message broker like ActiveMQ, Pulsar or RabbitMQ but also hosted services like Google Cloud Pub/Sub\footnote{\url{https://cloud.google.com/pubsub}} could be used for this task. However, these do not provide the end-to-end exactly-once\footnote{RabbitMQ has limited support for being used as exactly-once source but not as exactly-once sink since transactions are not supported~\cite{Apache.2020}. Pulsar can be used as exactly-once source using the same mechanism and as exactly-once sinks once transactions are implemented in Pulsar 2.7.0, therefore Pulsar could become a viable Kafka alternative for some applications in the future~\cite{StreamNative.2020}.} and ordering guarantees as well as stream retention required for correct and fault-tolerant stream processing. Log-based messaging systems, on the other hand, store stream records in order and can be used as exactly-once sources by including the record offset in checkpointed state. Kafka and Amazon Kinesis Data Streams\footnote{\url{https://aws.amazon.com/kinesis/data-streams/}} are two publicly available log-based stream transport platforms\footnote{The actual implementation of Kinesis Data Streams is unknown since it is a managed service, but because only appending is supported we regard it as log for all intents and purposes.}.

Kinesis Data Streams is a fully managed and reliable service hosted in the AWS cloud~\cite{AmazonWebServices.2020} and allows easy integration with other AWS offerings. The number of partitions per log, retention period and record encryption are the only configuration options. Up to \SI{1}{\mega\byte} or 1000 records can be produced to each partition per second, and up to \SI{2}{\mega\byte} can be consumed from each partition per second. Records can be retained for up to 7 days, which is sufficient to allow replay for fault tolerance in stream processing, but generally not enough for long-term retention to support data reprocessing in retrospect. While Kinesis Data Stream's operational costs are about four times lower than Kafka's, it lacks flexibility and throttles producers quickly~\cite{Nguyen.2018}.



\subsection{Apache Kafka}
Apache Kafka is a widely used~\cite{Apache.2020b} open-source stream transport platform first developed at LinkedIn. Kafka was the first system to leverage logs for high-throughput, low-latency messaging~\cite{Kreps.2011} and has been very influential on the design of modern stream processing platform by enabling fault-tolerance through replay~\cite[pp.~390--391]{Akidau.2018}. Records can be retained based on a time-based or size-based policy, with support for infinite retention which makes Kafka not only suitable for stream transport but also for persistent storage, or effectively a file system for streams. This enables streams which show the evolution of data as primary data source, instead of traditional tables which represent data at a specific point in time\footnote{This approach leverages the stream--table duality to \enquote{turn the database inside out}~\cites{Kleppmann.2015}[pp.~459--462]{Kleppmann.2017}[pp.~174--212]{Akidau.2018}}. For example, the New York Times stores all historic and present articles and assets like images and tags in a single Kafka partition for total order, and every update to content does not overwrite old data but is appended to the log~\cite{Svingen.2017}. For serving, the log is replayed from the beginning and an index is built for efficient lookup of content. However, Kafka is usually used as continuous event streaming platform. For in-depth information on development with and operation of Kafka as well as internals, refer to~\cite{Narkhede.2017}.

Nodes in a Kafka cluster are called \emph{brokers} and serve as distributed storage of \emph{topics}. Topics are Kafka's notion of streams that contain a certain event type, and each topic consists of one or more partitions.  The logical position of a record in a partition is called the offset. Records are guaranteed to be stored in the order they are appended to the log within a single partition, but not across partition of a topic. The retention period can be configured per-topic, with records exceeding the retention period being removed from the beginning of the log. Logs can also be compacted, which means that only the most recent record for a key is retained. This can make sense to keep log size small if applications are only interested in the most recent record for a key. Partitions can be replicated across the cluster for fault tolerance. Each partition has a broker acting as partition leader, which clients connect to to consume existing records or append new records to a partition log, as shown in figure \ref{fig:platforms-kafka-cluster}. Follower replicas do not serve client requests but replicate records from the leader, and can be promoted to become the new partition leader in case the current leader crashes. Only in-sync replicas, i.e. follower replicas that have caught up with the current leader, are eligible for leader election. Cluster metadata like broker membership, partition locations and topic configurations are stored in Zookeeper\footnote{\url{https://zookeeper.apache.org/}}, a distributed and highly reliable configuration service required to run Kafka. However, this dependency will be removed in future releases to simplify deployment.


\begin{figure}
	\centering
	% \includegraphics[width=0.55\textwidth]{plot_background_time_skew_events}
	FIGURE OF KAFKA CLUSTER WITH PARTITIONS, LEADERS AND REPLICATION
	\caption[Example of a dataflow graph]{Example of a dataflow graph: three streams are joined, transformed and emitted as a single stream}
	\label{fig:platforms-kafka-cluster}
\end{figure}

Kafka supports flexible consumption patterns using \emph{consumer groups} previously shown in \ref{fig:background-multiconsumer-patterns}. Each partition of a topic is assigned to one consumer in a consumer group. Therefore, load balancing can be achieved when every consumer belongs to the same consumer group. On the other hand, if all consumers are part of different consumer groups, every consumer receives all records for fan-out. Mixed patterns are also possible by having multiple consumer groups with multiple consumers. When using the load balancing pattern, Kafka effectively acts like a traditional message queue, whereas fan-out is more similar to publish--subscribe semantics. Offsets between consumers of a consumer group are coordinated via special topics, which becomes necessary when consumers within a group change and partitions need to be rebalanced between consumers. Consumers commit their offsets regularly to avoid duplicate consumption. An important design decision is the use of consumer polling instead of broker pushing of records. This allows consumers to control the pace of consumption and not be overwhelmed, but also enables replay of older records. Kafka brokers use a zero-copy method when serving consumers which means that Kafka sends records directly from disk to network without intermediate buffers, removing the performance overhead of copying and (de)compressing data. Multiple brokers called bootstrap servers can be specified in the consumer for the initial connection to the cluster, after which the consumer can ask for the desired partition leader.

Producers also use bootstrap servers to connect to the partition leader for appending records to the log. Producers can control how many replicas must have received the record before the write can be considered successful. A producer may not wait for a reply from the partition leader at all to achieve very high throughput. A producer may wait for a success reply from the leader to be able to retry in case of leader failure. At the highest level of write safety but also the highest latency, a producer may wait for all in-sync replicas to have received the message. Producers can also batch multiple records in one write request to improve throughput at the cost of latency. The partition a new record will be assigned to is determined by a partitioner. The default partitioner assigns partitions based on a key or at random if none is given, but custom partitioning strategies are supported. Depending on the configuration, records sent from a single producer may or may not be appended to the partition in the same order. Events must be serialized before being stored as binary payload in a record. Kafka provides basic serializers, but often custom serializers based on JSON or a generic serialization library like Avro\footnote{\url{https://avro.apache.org/}}, Google Protocol Buffers\footnote{\url{https://developers.google.com/protocol-buffers}} (also known as \emph{protobuf}) or Thrift\footnote{\url{https://thrift.apache.org/}} is used. Kafka also supports transactions for atomic writes of multiple records, which enables producers to implement exactly-once stream sinks. The prevent consumption of records of uncommitted transactions, consumers must support the isolation level directive.

Due to Kafka's popularity, a rich ecosystem of commercial offerings and libraries has emerged. Confluent, a company founded by one of the inventors of Kafka, provides a commercial Kafka platform with features like schema registries (centralized store for serialization schemas to be shared between consumers and producers) and tiered storage (offloading of old retained data from broker nodes to cheaper and scalable store like Amazon S3, also accelerating failure recovery and cluster rebalancing). Cloud platform providers like Amazon and Google also have fully managed offerings for Kafka, combining the flexibility and configurability of Kafka with the ease of operation of Kinesis Data Streams. Other tools like Kafka Connect allow the ingestion of streams from other systems to integrate Kafka into existing infrastructure landscapes, and even more tools exist to mirror whole clusters, monitor performance and availability or run queries on streams.





\section{Stream Processing Platforms}
storm
spark streaming
spark structured streaming
spark has good ML libraries
kafka streams
samza
wso2
esper
cloud dataflow hosted
comparison of frameworks: https://youtu.be/PiEQR9AXgl4

\cite{Shahverdi.2019} shows performance
add feature list

mention apache beam as higher level unified API running on top of these platforms
implementation of dataflow model



\subsection{Apache Flink}
flink is one of most capable open source platform
kinesis data analytics is hosted

\subsubsection{APIs}
datastream, dataset, SQL
async queries
event time
unit testing
watermarking strategies
transfer of dataflow model to flink triggers/evictors
beam runner

\subsubsection{Cluster}
workers and masters
task slots
high availability

\subsubsection{Execution Model}
tasks
operators
parallelism
co-location and operator chaining
shuffling after keyby
watermark propagation
backpressure sampling
shuffling

code evolution, switch live to newer version, recomputation only possible of data are retained, but same with batch

\subsubsection{State}
state backends
broadcast state

\subsubsection{Checkpointing}
barriers
aligned and unaligned, difference if IO or compute is bottleneck
checkpoint for fault tolerance
savepoint for reconfiguration and code changes


\subsubsection{Network Stack}
backpressure handling
flow control
latency vs throughput
https://flink.apache.org/2019/06/05/flink-network-stack.html

\subsubsection{Flink + Kafka}
replay
partitioning
high availability

also managed versions on AWS, but set up ourselves to understand better


