After having regarded the theoretical foundations of streaming, we now look at existing implementations of stream transport and processing platforms that are available to the public (some companies have custom platforms for internal use only). We will present them under the aspects of correctness, fault tolerance, latency and scalability.





\section{Stream Transport Platforms}
Stream transport platforms are responsible for moving streams between producers and consumers, but may also store them for replay. Theoretically, any message queue or publish--subscribe message broker like ActiveMQ, Pulsar or RabbitMQ but also hosted services like Google Cloud Pub/Sub\footnote{\url{https://cloud.google.com/pubsub}} could be used for this task. However, these do not provide the end-to-end exactly-once\footnote{RabbitMQ has limited support for being used as exactly-once source but not as exactly-once sink since transactions are not supported~\cite{Apache.2020}. Pulsar can be used as exactly-once source using the same mechanism and as exactly-once sinks once transactions are implemented in Pulsar 2.7.0, therefore Pulsar could become a viable Kafka alternative for some applications in the future~\cite{StreamNative.2020}.} and ordering guarantees as well as stream retention required for correct and fault-tolerant stream processing. Log-based messaging systems, on the other hand, store stream records in order and can be used as exactly-once sources by including the record offset in checkpointed state. Kafka and Amazon Kinesis Data Streams\footnote{\url{https://aws.amazon.com/kinesis/data-streams/}} are two publicly available log-based stream transport platforms\footnote{The actual implementation of Kinesis Data Streams is unknown since it is a managed service, but because only appending is supported we regard it as log for all intents and purposes.}.

Kinesis Data Streams is a fully managed and reliable service hosted in the AWS cloud~\cite{AmazonWebServices.2020} and allows easy integration with other AWS offerings. The number of partitions per log, retention period and record encryption are the only configuration options. Up to \SI{1}{\mega\byte} or 1000 records can be produced to each partition per second, and up to \SI{2}{\mega\byte} can be consumed from each partition per second. Records can be retained for up to 7 days, which is sufficient to allow replay for fault tolerance in stream processing, but generally not enough for long-term retention to support data reprocessing in retrospect. While Kinesis Data Stream's operational costs are about four times lower than Kafka's, it lacks flexibility and throttles producers quickly~\cite{Nguyen.2018}.



\subsection{Apache Kafka}
Apache Kafka is a widely used~\cite{Apache.2020b} open-source stream transport platform first developed at LinkedIn. Kafka was the first system to leverage logs for high-throughput, low-latency messaging~\cite{Kreps.2011} and has been very influential on the design of modern stream processing platform by enabling fault-tolerance through replay~\cite[pp.~390--391]{Akidau.2018}. Records can be retained based on a time-based or size-based policy, with support for infinite retention which makes Kafka not only suitable for stream transport but also for persistent storage, effectively making it a file system for streams. This enables streams which show the evolution of data as primary data source, instead of traditional tables which represent data at a specific point in time\footnote{This approach leverages the stream--table duality to \enquote{turn the database inside out}~\cites{Kleppmann.2015}[pp.~459--462]{Kleppmann.2017}[pp.~174--212]{Akidau.2018}}. For example, the New York Times stores all historic and present articles and assets like images and tags in a single Kafka partition for total order, and every update to content does not overwrite old data but is appended to the log~\cite{Svingen.2017}. For serving, the log is replayed from the beginning and an index is built for efficient lookup of content. However, Kafka is usually used as continuous event streaming platform. For in-depth information on development with and operation of Kafka as well as internals, refer to~\cite{Narkhede.2017}.

Nodes in a Kafka cluster are called \emph{brokers} and serve as distributed storage of \emph{topics}. Topics are Kafka's notion of streams that contain a certain event type, and each topic consists of one or more partitions.  The logical position of a record in a partition is called the offset. Records are guaranteed to be stored in the order they are appended to the log within a single partition, but not across partition of a topic. The retention period can be configured per-topic, with records exceeding the retention period being removed from the beginning of the log. Logs can also be compacted, which means that only the most recent record for a key is retained. This can make sense to keep log size small if applications are only interested in the most recent record for a key. Partitions can be replicated across the cluster for fault tolerance. Each partition has a broker acting as partition leader, which clients connect to to consume existing records or append new records to a partition log, as shown in figure \ref{fig:platforms-kafka-cluster}. Follower replicas do not serve client requests but replicate records from the leader, and can be promoted to become the new partition leader in case the current leader crashes. Only in-sync replicas, i.e. follower replicas that have caught up with the current leader, are eligible for leader election. Cluster metadata like broker membership, partition locations and topic configurations are stored in Zookeeper\footnote{\url{https://zookeeper.apache.org/}}, a distributed and highly reliable configuration service required to run Kafka. However, this dependency will be removed in future releases to simplify deployment.


\begin{figure}
	\centering
	% \includegraphics[width=0.55\textwidth]{plot_background_time_skew_events}
	FIGURE OF KAFKA CLUSTER WITH PARTITIONS, LEADERS AND REPLICATION
	\caption[Structure of a Kafka cluster]{Structure of a Kafka cluster: Partitions are spread across brokers acting as leader and follower replicas}
	\label{fig:platforms-kafka-cluster}
\end{figure}

Kafka supports flexible consumption patterns using \emph{consumer groups} previously shown in \ref{fig:background-multiconsumer-patterns}. Each partition of a topic is assigned to one consumer in a consumer group. Therefore, load balancing can be achieved when every consumer belongs to the same consumer group. On the other hand, if all consumers are part of different consumer groups, every consumer receives all records for fan-out. Mixed patterns are also possible by having multiple consumer groups with multiple consumers. When using the load balancing pattern, Kafka effectively acts like a traditional message queue, whereas fan-out is more similar to publish--subscribe semantics. Offsets between consumers of a consumer group are coordinated via special topics, which becomes necessary when consumers within a group change and partitions need to be rebalanced between consumers. Consumers commit their offsets regularly to avoid duplicate consumption. An important design decision is the use of consumer polling instead of broker pushing of records. This allows consumers to control the pace of consumption and not be overwhelmed, but also enables replay of older records. Kafka brokers use a zero-copy method when serving consumers, which means that Kafka sends records directly from disk to network without intermediate buffers, which is enabled by using the wire format for storage. Multiple brokers called bootstrap servers can be specified in the consumer for the initial connection to the cluster, after which the consumer can ask for the desired partition leader.

Producers also use bootstrap servers to connect to the partition leader for appending records to the log. Producers can control how many replicas must have received the record before the write can be considered successful. A producer may not wait for a reply from the partition leader at all to achieve very high throughput. A producer may wait for a success reply from the leader to be able to retry in case of leader failure. At the highest level of write safety but also the highest latency, a producer may wait for all in-sync replicas to have received the message. Producers can also batch multiple records in one write request to improve throughput at the cost of latency. The partition a new record will be assigned to is determined by a partitioner. The default partitioner assigns partitions based on a key like a user identifier or at random if none is given, but custom partitioning strategies are supported. Depending on the configuration, records sent from a single producer may or may not be appended to the partition in the same order. Events must be serialized before being stored as binary payload in a record. Kafka provides basic serializers, but often custom serializers based on JSON or a generic serialization library like Avro\footnote{\url{https://avro.apache.org/}}, Google Protocol Buffers\footnote{\url{https://developers.google.com/protocol-buffers}} (also known as \emph{protobuf}) or Thrift\footnote{\url{https://thrift.apache.org/}} is used. Kafka also supports transactions for atomic writes of multiple records across multiple partitions, which enables producers to implement exactly-once stream sinks. The prevent consumption of records of uncommitted transactions, consumers must support the isolation level directive.

Due to Kafka's popularity, a rich ecosystem of commercial offerings and libraries has emerged. Confluent, a company founded by one of the inventors of Kafka, provides a commercial Kafka platform with features like schema registries (centralized store for serialization schemas to be shared between consumers and producers) and tiered storage (offloading of old retained data from broker nodes to cheaper and scalable store like Amazon S3, also accelerating failure recovery and cluster rebalancing). Cloud platform providers like Amazon and Google also have fully managed offerings for Kafka, combining the flexibility and configurability of Kafka with the ease of operation of Kinesis Data Streams. Other tools like Kafka Connect allow the ingestion of streams from other systems to integrate Kafka into existing technology landscapes, and even more tools exist to mirror whole clusters, monitor performance and availability or run queries on streams.





\section{Stream Processing Platforms}
Stream processing platforms are also part of the stream transport platform ecosystem, consuming and producing streams while doing processing in between. They can also act as bridge between different transport platforms. The platform facilitates the development of processing jobs by taking care of aspects like event-time ordering, fault tolerance of state and scalability, and providing APIs to perform transformations on streams like windowing or pattern recognition. There is a number of frameworks with different approaches and paradigms that have been tried over time, refer to \cite{Fragkoulis.2020} for a comprehensive overview of the evolution and features of stream processing systems. We will focus on modern frameworks that can guarantee correct and consistent results through exactly-once processing. Therefore, we will not regard Samza\footnote{\url{http://samza.apache.org/}} (which only supports at-least-once processing), Spark Streaming (which has no support for event-time ordering and uses micro-batching) and Storm (although rudimentary stateful processing is supported with the Trident extension). However, they might still be suitable for certain applications. For example, Spark Streaming can leverage the extensive machine learning features of the Spark ecosystem. Kafka Streams\footnote{\url{https://kafka.apache.org/documentation/streams/}}, Spark Structured Streaming\footnote{\url{https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html}}, Hazelcast Jet\footnote{\url{https://jet-start.sh/}} and Flink are open-source stream processing frameworks which are suitable for stream analytics. All frameworks support high throughput and low latency, but exact numbers depend on the workload and configuration and will therefore not be compared here. Some performance results are shown in~\cite{Shahverdi.2019}. Note that all frameworks are under active development and new features are developed constantly, therefore existing limitations might be overcome.

Kafka Streams is a lightweight processing framework designed to run alongside the transport cluster, simplifying deployment because no separate cluster is needed but limiting it to Kafka as stream transport platform. Low-latency exactly-once processing with event-time ordering is supported. State can be stored in special compacted changelog topics for fault tolerance and queried from external applications. Kafka Streams also transparently handles rebalancing of partitions when adding and removing processing instances through consumer groups. Kafka Streams applications perform stateless or stateful transformations on stream and table abstractions as well as joining and windowing. While not having the flexibility of the Dataflow mode, windowing in Kafka streams supports all three common window types and early/late triggers. In general, Kafka Streams is suitable for many processing types but is limited to Kafka sources and sinks, and the simple deployment lacks flexibility.

Spark Structured Streaming is a stream processing API built on top of the Spark batch processing framework. Jobs can be submitted to regular Spark clusters and run there in a scalable and fault-tolerant fashion. Kafka and Kinesis Data Streams can be used as stream sources and sinks. Jobs can be run in two modes. Exactly-once processing can be guaranteeed in micro-batching mode, while only at-least-once processing is possible in continuous processing mode. However, latencies can only be as low as \SI{100}{\milli\second} in micro-batching mode whereas latencies of \SI{1}{\milli\second} can be achieved with continuous processing. Spark Structured Streaming supports all common stream operations, but uses the latest event timestamp as watermark, which can lead to incorrectly discarded data in case of varying event-time skew~\cite[p.~386]{Akidau.2018}. Spark Structured Streaming does not use a dataflow graph processing model but uses an incremental version of the static queries on an unbounded table from the batch API~\cite[p.~601]{Armbrust.2018}. Compared to other frameworks, Spark Structured Streaming has not many unique advantages. However, stream processing jobs can be run on an existing Spark cluster and existing developer know-how from Spark batch jobs can be applied to Spark Structured Streaming.

Hazelcast Jet is the the newest of the four frameworks, having been released in 2018 with focus on high performance and easy maintenance~\cite{Hazelcast.2017}. Hazelcast Jet is built on top of the Hazelcast In-Memory Data Grid to support distributed in-memory data structures and lookups for stream enrichment. Jobs can be run on a a cluster for scalability and fault tolerance. The framework comes with many connectors for sources and sinks, and supports exactly-once processing with Kafka. While it has no SQL-like API, common stream operations with event-time ordering are supported, including early triggers. It also integration with change data capture software for relational databases, and supports batch processing with a similar API to stream processing. Coroutines with shared threads instead of individual threads are used for executing tasks, maximizing CPU utilization and reducing context switching overhead. Hazelcast Jet is a promising stream processing engine, but still immature due to its young age.

While Beam\footnote{\url{https://beam.apache.org/}} is not a stream processing engine, it is still worth mentioning in this context. Beam is an abstraction layer that allows to write stream and batch processing jobs which can be executed on a number of stream execution frameworks, including Flink, Hazelcast Jet, Spark and Samza but also Google's fully managed Cloud Dataflow\footnote{\url{https://cloud.google.com/dataflow/}} platform. Beam is one implementation of the Dataflow paper~\cite{TylerAkidau.2015} and therefore provides an API for all windowing concepts presented earlier. While Beam was designed as portability layer for jobs, the exact features like exactly-once processing and window output modes are dependent on the underlying stream execution framework.



\subsection{Apache Flink}
flink is one of most capable open source platform
kinesis data analytics is hosted
Ververica Platform is commercial distribution

\subsubsection{APIs}
datastream, dataset, SQL
async queries
event time
unit testing
watermarking strategies
transfer of dataflow model to flink triggers/evictors
beam runner

\subsubsection{Cluster}
workers and masters
task slots
high availability

\subsubsection{Execution Model}
tasks
operators
parallelism
co-location and operator chaining
shuffling after keyby
watermark propagation
backpressure sampling
shuffling

code evolution, switch live to newer version, recomputation only possible of data are retained, but same with batch

\subsubsection{State}
state backends
broadcast state
queryable

\subsubsection{Checkpointing}
barriers
aligned and unaligned, difference if IO or compute is bottleneck
checkpoint for fault tolerance
savepoint for reconfiguration and code changes


\subsubsection{Network Stack}
backpressure handling
flow control
latency vs throughput
https://flink.apache.org/2019/06/05/flink-network-stack.html

\subsubsection{Flink + Kafka}
replay
partitioning
high availability

also managed versions on AWS, but set up ourselves to understand better


